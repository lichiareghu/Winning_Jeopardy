{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "import numpy as np\n",
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#read the input file\n",
    "jeopardy = pd.read_csv(\"jeopardy.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Show Number</th>\n",
       "      <th>Air Date</th>\n",
       "      <th>Round</th>\n",
       "      <th>Category</th>\n",
       "      <th>Value</th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>HISTORY</td>\n",
       "      <td>$200</td>\n",
       "      <td>For the last 8 years of his life, Galileo was ...</td>\n",
       "      <td>Copernicus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>ESPN's TOP 10 ALL-TIME ATHLETES</td>\n",
       "      <td>$200</td>\n",
       "      <td>No. 2: 1912 Olympian; football star at Carlisl...</td>\n",
       "      <td>Jim Thorpe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>EVERYBODY TALKS ABOUT IT...</td>\n",
       "      <td>$200</td>\n",
       "      <td>The city of Yuma in this state has a record av...</td>\n",
       "      <td>Arizona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>THE COMPANY LINE</td>\n",
       "      <td>$200</td>\n",
       "      <td>In 1963, live on \"The Art Linkletter Show\", th...</td>\n",
       "      <td>McDonald's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>EPITAPHS &amp; TRIBUTES</td>\n",
       "      <td>$200</td>\n",
       "      <td>Signer of the Dec. of Indep., framer of the Co...</td>\n",
       "      <td>John Adams</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Show Number    Air Date      Round                         Category  Value  \\\n",
       "0         4680  2004-12-31  Jeopardy!                          HISTORY   $200   \n",
       "1         4680  2004-12-31  Jeopardy!  ESPN's TOP 10 ALL-TIME ATHLETES   $200   \n",
       "2         4680  2004-12-31  Jeopardy!      EVERYBODY TALKS ABOUT IT...   $200   \n",
       "3         4680  2004-12-31  Jeopardy!                 THE COMPANY LINE   $200   \n",
       "4         4680  2004-12-31  Jeopardy!              EPITAPHS & TRIBUTES   $200   \n",
       "\n",
       "                                            Question      Answer  \n",
       "0  For the last 8 years of his life, Galileo was ...  Copernicus  \n",
       "1  No. 2: 1912 Olympian; football star at Carlisl...  Jim Thorpe  \n",
       "2  The city of Yuma in this state has a record av...     Arizona  \n",
       "3  In 1963, live on \"The Art Linkletter Show\", th...  McDonald's  \n",
       "4  Signer of the Dec. of Indep., framer of the Co...  John Adams  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jeopardy.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Show Number', ' Air Date', ' Round', ' Category', ' Value',\n",
       "       ' Question', ' Answer'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jeopardy.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "jeopardy.columns = ['Show Number', 'Air Date', 'Round', 'Category', 'Value',\n",
    "       'Question', 'Answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Show Number', 'Air Date', 'Round', 'Category', 'Value', 'Question',\n",
       "       'Answer'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jeopardy.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define function to normalise the text (make lower case and remove punctuation)\n",
    "def text_norm(x):\n",
    "    lower = x.lower()\n",
    "    # fromkeys will generate a dict with keys as punctuation and values as space\n",
    "    # maketrans will create transition values for all\n",
    "    # translate will replace all the characters with space based on the maketrans table\n",
    "    n_lower = lower.translate(str.maketrans(dict.fromkeys(string.punctuation,'')))\n",
    "    return(n_lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clean_question = jeopardy['Question'].apply(text_norm)\n",
    "clean_answer = jeopardy['Answer'].apply(text_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Define function to normalise values, ie remove the dollor sign and convert to int and handle errors as zero\n",
    "def value_norm(x):\n",
    "    # Remove dollar sign\n",
    "    temp = x.translate(str.maketrans(dict.fromkeys(string.punctuation,'')))\n",
    "    # Convert to int\n",
    "    try:\n",
    "        temp = int(temp)\n",
    "    except:\n",
    "        temp = 0\n",
    "    return(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clean_value = jeopardy['Value'].apply(value_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clean_Air_Date = pd.to_datetime(jeopardy['Air Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Create columns for clean values\n",
    "jeopardy.insert(len(jeopardy.columns),'clean_question',clean_question,True)\n",
    "jeopardy.insert(len(jeopardy.columns),'clean_answer',clean_answer,True)\n",
    "jeopardy.insert(len(jeopardy.columns),'clean_value',clean_value,True)\n",
    "jeopardy.insert(len(jeopardy.columns),'clean_Air_Date',clean_Air_Date,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Calculate the % of words in answer that also appear in question\n",
    "def tokenize(x):\n",
    "    split_question = x['clean_question'].split(\" \") \n",
    "    split_answer = x['clean_answer'].split(\" \") \n",
    "    match_count = 0\n",
    "    while 'the' in split_answer:\n",
    "        split_answer.remove('the')\n",
    "        \n",
    "    if len(split_answer) == 0:\n",
    "        return(0)\n",
    "    else:\n",
    "        for i in split_answer:\n",
    "             if i in split_question:\n",
    "                    match_count = match_count+1 \n",
    "    \n",
    "    return(match_count/len(split_answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "answer_in_question = jeopardy.apply(tokenize,axis=1)\n",
    "jeopardy.insert(len(jeopardy.columns),'answer_in_question',answer_in_question,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05973712438535679"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_in_question_mean = answer_in_question.mean()\n",
    "answer_in_question_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So, we might say that, from the dataset, on an average there is a 5.9 percent chance that we can find the answer in the question as well....\n",
    "### To see how often the questions are repeated, we might check the question for words with more than 6 characters and see how often these are used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Sort the dataset datewise\n",
    "jeopardy.sort_values(['clean_Air_Date'],axis = 0,ascending = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question_overlap_mean: 0.687124288096678\n"
     ]
    }
   ],
   "source": [
    "question_overlap = []\n",
    "terms_used = set()\n",
    "#Get each row in jeopardy\n",
    "for index,row in jeopardy.iterrows():\n",
    "    split_question = row['clean_question'].split(\" \")\n",
    "    terms = [i for i in split_question if len(i)>5]\n",
    "    match_count = 0\n",
    "    #Count the number of terms that are not already available in terms_used\n",
    "    for i in terms:\n",
    "        if i in terms_used:\n",
    "            match_count = match_count+1\n",
    "    #Add all the terms in the new question to the terms_used\n",
    "    #It is very important that you count the words per question. \n",
    "    #So add all the words to the terms_used after counting\n",
    "    for i in terms:\n",
    "        terms_used.add(i)\n",
    "    #If there are cases with zero length, the number of new words added to the list should be zero\n",
    "    if len(terms) > 0:\n",
    "        temp = match_count/len(terms)\n",
    "    else:\n",
    "        temp = match_count = 0\n",
    "    #Append the value for every question   \n",
    "    question_overlap.append(temp)\n",
    "\n",
    "\n",
    "jeopardy['question_overlap'] = question_overlap  \n",
    "question_overlap_mean = jeopardy['question_overlap'].mean()\n",
    "print('question_overlap_mean:',question_overlap_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From the question_overlap_mean, we can assume that 68.7% of the words  in every new question added are already available in the list of words used. \n",
    "### This might mean that the questions are repeated quite a lot. But we are not very sure, since we are only checking for individual words and not prases..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets not try and identify some high value questions with the help of Chi Sqared Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def value(x):\n",
    "    value = 0 if x['clean_value']<800 else 1\n",
    "    return (value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19999, 19999)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "high_value = jeopardy.apply(value,axis = 1)\n",
    "high_value.size,len(jeopardy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "jeopardy['high_value'] = high_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Function to count the high and low value questions for each word in the terms_used\n",
    "def que_count(x):\n",
    "    low_count = 0\n",
    "    high_count = 0\n",
    "    for index,row in jeopardy.iterrows():\n",
    "        split_question = row['clean_question'].split(\" \")\n",
    "        if (x in split_question) and row['high_value'] == 1 :\n",
    "            high_count = high_count+1\n",
    "        if (x in split_question) and row['high_value'] == 0 :\n",
    "            low_count = low_count+1\n",
    "    return (high_count,low_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#picking 10 random terms from terms_used\n",
    "terms_list = list (terms_used)\n",
    "comparison_terms = []\n",
    "for i in range(10):\n",
    "    n = np.random.randint(0,len(terms_list))\n",
    "    comparison_terms.append(terms_list[n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['vivien',\n",
       " 'couple',\n",
       " 'turgenevs',\n",
       " 'stempel',\n",
       " 'mutineers',\n",
       " 'berries',\n",
       " 'cambrai',\n",
       " 'albondigas',\n",
       " 'savonius',\n",
       " 'nursery']"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparison_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "observed_expected = []\n",
    "for i in comparison_terms:\n",
    "    h,l = que_count(i)\n",
    "    observed_expected.append([h,l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 1],\n",
       " [5, 9],\n",
       " [1, 0],\n",
       " [1, 0],\n",
       " [1, 0],\n",
       " [0, 4],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [2, 7]]"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Observe the frequencies of occurances of words\n",
    "observed_expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>high_value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>high_value</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0       high_value\n",
       "high_value            \n",
       "0                11285\n",
       "1                 8714"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the total percentages count the high value and low value questions\n",
    "count = pd.crosstab(jeopardy['high_value'],columns = ['high_value'])\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11285, 8714)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "low_value_count,high_value_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "low_value_count = count['high_value'][0]\n",
    "high_value_count = count['high_value'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "chi_squared = []\n",
    "\n",
    "for i in observed_expected:\n",
    "    #Get the total number of questions in which the term appears\n",
    "    total = sum(i)\n",
    "    #Get the % of questions containing the term w.r.t the total dataset\n",
    "    total_prop = total/len(jeopardy)\n",
    "    #Get the expected count of a particular term can be got by multiplying the propotion with the total count of high and low values questions respectively\n",
    "    high_value_exp = total_prop* high_value_count\n",
    "    low_value_exp = total_prop * low_value_count\n",
    "    expected = [high_value_exp,low_value_exp]\n",
    "    #use scipy.stats.chisqare to calculate the observed/expected values\n",
    "    chi_squared.append(scipy.stats.chisquare(i,expected))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Power_divergenceResult(statistic=0.7721754541426672, pvalue=0.3795448984353682),\n",
       " Power_divergenceResult(statistic=0.35159094969782123, pvalue=0.5532139107905136),\n",
       " Power_divergenceResult(statistic=1.295042460408538, pvalue=0.25512076479610835),\n",
       " Power_divergenceResult(statistic=1.295042460408538, pvalue=0.25512076479610835),\n",
       " Power_divergenceResult(statistic=1.295042460408538, pvalue=0.25512076479610835),\n",
       " Power_divergenceResult(statistic=3.088701816570669, pvalue=0.07883768176626049),\n",
       " Power_divergenceResult(statistic=0.7721754541426672, pvalue=0.3795448984353682),\n",
       " Power_divergenceResult(statistic=1.295042460408538, pvalue=0.25512076479610835),\n",
       " Power_divergenceResult(statistic=0.7721754541426672, pvalue=0.3795448984353682),\n",
       " Power_divergenceResult(statistic=1.6685296771805387, pvalue=0.1964555878559714)]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chi_squared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This shows that the mean of sqared differences between the observed and expected frequencies of these terms are all very small. So ideally, if the words were a deciding factor in the value of the question, there would be significant differences in the observed and expected values, which is not the case here."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
